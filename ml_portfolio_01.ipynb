{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9uwZj4qJcn7"
      },
      "source": [
        "# Note\n",
        "\n",
        "The Machine Learning methods presented here are only some of the ways of approaching the portfolio optimization problem. There are multiple ways of incoporating ML in the financial models and it is up to you to come up with more interesting and appropriate approaches. We have tried to use multiple ML models in different sections as an example.\n",
        "\n",
        "The general rule of thumb in the approaches is as follows:\n",
        "- Use non-linear regression for predicting future values of stocks\n",
        "- Use appropriate linear regression for financial models (Single Index, CAPM) according to their standard formulas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJuGS56CJcn9"
      },
      "source": [
        "# Load your data\n",
        "\n",
        "We present here a basic way of importing stock data which will be used in the subsequent sections."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_F3WvVuxJcn9",
        "outputId": "ceb6c6d8-c991-4cc2-bcc6-5ce0ffe7dfa2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Market Index Data:\n",
            "                   Open         High          Low        Close    Adj Close  \\\n",
            "Date                                                                          \n",
            "2018-06-29  2727.129883  2743.260010  2718.030029  2718.370117  2718.370117   \n",
            "2018-07-02  2704.949951  2727.260010  2698.949951  2726.709961  2726.709961   \n",
            "2018-07-03  2733.270020  2736.580078  2711.159912  2713.219971  2713.219971   \n",
            "2018-07-05  2724.189941  2737.830078  2716.020020  2736.610107  2736.610107   \n",
            "2018-07-06  2737.679932  2764.409912  2733.520020  2759.820068  2759.820068   \n",
            "\n",
            "                Volume  \n",
            "Date                    \n",
            "2018-06-29  3586800000  \n",
            "2018-07-02  3095040000  \n",
            "2018-07-03  1911460000  \n",
            "2018-07-05  2980160000  \n",
            "2018-07-06  2590250000  \n",
            "\n",
            "Google Data:\n",
            "                 Open       High        Low      Close  Adj Close    Volume\n",
            "Date                                                                       \n",
            "2018-06-29  56.615501  57.068001  56.351002  56.459499  56.459499  31562000\n",
            "2018-07-02  55.767502  57.149502  55.330002  57.105499  57.105499  23216000\n",
            "2018-07-03  57.471001  57.495499  55.721500  55.813999  55.813999  16448000\n",
            "2018-07-05  56.230000  57.207001  56.155998  57.064499  57.064499  28594000\n",
            "2018-07-06  57.088501  57.810001  56.862000  57.754002  57.754002  21820000\n",
            "\n",
            "Apple Data:\n",
            "                 Open       High        Low      Close  Adj Close    Volume\n",
            "Date                                                                       \n",
            "2018-06-29  46.572498  46.797501  45.727501  46.277500  44.226265  90950800\n",
            "2018-07-02  45.955002  46.825001  45.855000  46.794998  44.720833  70925200\n",
            "2018-07-03  46.947498  46.987499  45.884998  45.980000  43.941948  55819200\n",
            "2018-07-05  46.314999  46.602501  46.070000  46.349998  44.295547  66416800\n",
            "2018-07-06  46.355000  47.107498  46.299999  46.992500  44.909584  69940800\n"
          ]
        }
      ],
      "source": [
        "import yfinance as yf\n",
        "import datetime\n",
        "# Define the ticker symbols for the market index and individual assets\n",
        "market_index_ticker = \"^GSPC\"  # S&P 500 index\n",
        "google_ticker = \"GOOGL\"  # Google\n",
        "apple_ticker = \"AAPL\"  # Apple\n",
        "\n",
        "# Define the start and end dates for the historical data\n",
        "end_date = datetime.datetime.now()\n",
        "start_date = end_date - datetime.timedelta(days=5*365)\n",
        "\n",
        "# Fetch the historical data using yfinance\n",
        "market_index_data = yf.download(\n",
        "    market_index_ticker, start=start_date, end=end_date)\n",
        "google_data = yf.download(google_ticker, start=start_date, end=end_date)\n",
        "apple_data = yf.download(apple_ticker, start=start_date, end=end_date)\n",
        "\n",
        "# Print the fetched data\n",
        "print(\"Market Index Data:\")\n",
        "print(market_index_data.head())\n",
        "print(\"\\nGoogle Data:\")\n",
        "print(google_data.head())\n",
        "print(\"\\nApple Data:\")\n",
        "print(apple_data.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-jJpWaVJcn-"
      },
      "source": [
        "# Mean Variance Optimization\n",
        "\n",
        "- Load the stock prices for your selected stocks\n",
        "- Divide data into independent variable X (10 consecutive days of stock values), and dependent variable y (stock value at 10th day into future)\n",
        "- Train non linear regression model to predict stock value 10 day into the future\n",
        "- Use the 10 future stock values and apply mean-variance optimization using pypfopt module"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPortfolioOpt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qySs2O1fyQz",
        "outputId": "0e2d0e3f-52d7-4aa2-b50a-c0eccce6cee4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPortfolioOpt\n",
            "  Downloading pyportfolioopt-1.5.5-py3-none-any.whl (61 kB)\n",
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/61.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m61.9/61.9 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cvxpy<2.0.0,>=1.1.19 in /usr/local/lib/python3.10/dist-packages (from PyPortfolioOpt) (1.3.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from PyPortfolioOpt) (1.22.4)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.10/dist-packages (from PyPortfolioOpt) (1.5.3)\n",
            "Requirement already satisfied: scipy<2.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from PyPortfolioOpt) (1.10.1)\n",
            "Requirement already satisfied: osqp>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from cvxpy<2.0.0,>=1.1.19->PyPortfolioOpt) (0.6.2.post8)\n",
            "Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.10/dist-packages (from cvxpy<2.0.0,>=1.1.19->PyPortfolioOpt) (2.0.12)\n",
            "Requirement already satisfied: scs>=1.1.6 in /usr/local/lib/python3.10/dist-packages (from cvxpy<2.0.0,>=1.1.19->PyPortfolioOpt) (3.2.3)\n",
            "Requirement already satisfied: setuptools>65.5.1 in /usr/local/lib/python3.10/dist-packages (from cvxpy<2.0.0,>=1.1.19->PyPortfolioOpt) (67.7.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.19->PyPortfolioOpt) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.19->PyPortfolioOpt) (2022.7.1)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.10/dist-packages (from osqp>=0.4.1->cvxpy<2.0.0,>=1.1.19->PyPortfolioOpt) (0.1.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=0.19->PyPortfolioOpt) (1.16.0)\n",
            "Installing collected packages: PyPortfolioOpt\n",
            "Successfully installed PyPortfolioOpt-1.5.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnYPm9yTJcn_",
        "outputId": "99fdf1ed-926e-4854-ae83-811377509c93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "apple    -0.067769\n",
            "google   -1.134717\n",
            "Name: mkt, dtype: float64\n",
            "OrderedDict([('apple', 0.5), ('google', 0.5)])\n"
          ]
        }
      ],
      "source": [
        "from pypfopt import plotting\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from pypfopt import expected_returns, risk_models, EfficientFrontier\n",
        "\n",
        "\n",
        "apple_prices = apple_data['Close'].tolist()\n",
        "google_prices = google_data['Close'].tolist()\n",
        "\n",
        "# Dependent variable - 10 consecutive days of stock prices\n",
        "apple_x = [apple_prices[i:i+10] for i in range(len(apple_prices)-20)]\n",
        "# Independent variable - stock price 10th day into the future\n",
        "apple_y = [apple_prices[i+10] for i in range(10,len(apple_prices)-10)]\n",
        "\n",
        "apple_test = [apple_prices[i:i+10] for i in range(len(apple_prices)-20,len(apple_prices)-10)]\n",
        "\n",
        "reg = RandomForestRegressor()\n",
        "reg.fit(apple_x,apple_y)\n",
        "# Predict stock price for 10 future days\n",
        "apple = reg.predict(apple_test)\n",
        "\n",
        "google_x = [google_prices[i:i+10] for i in range(len(google_prices)-20)]\n",
        "google_y = [google_prices[i+10] for i in range(10,len(google_prices)-10)]\n",
        "\n",
        "google_test = [google_prices[i:i+10] for i in range(len(google_prices)-20,len(google_prices)-10)]\n",
        "\n",
        "reg = RandomForestRegressor()\n",
        "reg.fit(google_x,google_y)\n",
        "google = reg.predict(google_test)\n",
        "\n",
        "future_prices = {'apple':apple,'google':google}\n",
        "future_prices = pd.DataFrame(future_prices)\n",
        "\n",
        "\n",
        "# Construct covariance matrix of future stock prices\n",
        "# cov_matrix = risk_models.sample_cov(future_prices)\n",
        "S = risk_models.CovarianceShrinkage(future_prices).ledoit_wolf()\n",
        "# plotting.plot_covariance(S, plot_correlation=True)\n",
        "\n",
        "# Use capm to find expected returns on future prices\n",
        "mu = expected_returns.capm_return(future_prices)\n",
        "print(mu)\n",
        "# Do mean variance optimization using efficient frontier\n",
        "ef = EfficientFrontier(mu, S)\n",
        "ef.min_volatility()\n",
        "weights = ef.clean_weights()\n",
        "print(weights)\n",
        "# weights = ef.max_sharpe(risk_free_rate=0.02)\n",
        "# cleaned_weights = ef.clean_weights()\n",
        "# print(cleaned_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJh5tKc3Jcn_"
      },
      "source": [
        "# Single Index Model\n",
        "\n",
        "- Load the stock prices for your selected stocks\n",
        "- Divide data into independent variable X (10 consecutive days of market index values), and dependent variable y (market index value at 10th day into future)\n",
        "- Train non linear regression model to predict market index value 10 day into the future\n",
        "- Fit separate linear models each for a stock according to formula of single index model\n",
        "- The index model can\n",
        "be written as the following regression equation:\n",
        "\n",
        " $$R_{i}(t) = \\alpha_{i} + \\beta_{i}R_{M}(t) + e_{i}(t)$$\n",
        " Since, $E(e_{i}) = 0$\n",
        " $$E(R_{i}) = \\alpha_{i} + \\beta_{i}E(R_{M})$$\n",
        "- Use the return values of the stock(y) and the market(x) and fit a linear regression model\n",
        "- Compare the coefficients of the fitted line to find $\\alpha_{i}$ and $\\beta_{i}$\n",
        "- Use 10 predicted market returns to predict returns of each stock\n",
        "- Use the Treynor Black model for portfolio optimization\n",
        "- Step 1: $$w_{i}^{0} = \\frac{\\alpha_{i}}{\\sigma^{2}(e_{i})}$$\n",
        "- Step 2: $$w_{i} = \\frac{w_{i}^{0}}{\\sum w_{i}^{0}}$$\n",
        "- Step 3: $$\\alpha_{A} = \\sum w_{i}\\alpha_{i}$$\n",
        "- Step 4: $$\\sigma^{2}(e_{A}) = \\sum w_{i}^{2}\\sigma^{2}(e_{i})$$\n",
        "- Step 5: $$w_{A}^{0} = \\frac{\\alpha_{A}/\\sigma^{2}(e_{A})}{E(R_{m})/\\sigma^{2}_{M}}$$\n",
        "- Step 6: $$\\beta_{A} = \\sum w_{i}\\beta_{i}$$\n",
        "- Step 7: $$w_{A}^{*} = \\frac{w_{A}^{0}}{1+(1-\\beta_{A})w_{A}^{0}}$$\n",
        "- Step 8: $$w_{M}^{*} = 1-w_{A}^{*}$$\n",
        "$$w_{i}^{*} = w_{A}^{*}w_{i}$$\n",
        "- Step 9: $$E(R_{P}) = (w_{M}^{*}+w_{A}^{*}\\beta_{A})E(R_{M}) +w_{A}^{*}\\alpha_{A}$$\n",
        "- Step 10: $$\\sigma_{P}^{2} = (w_{M}^{*}+w_{A}^{*}\\beta_{A})^{2}\\sigma_{M}^{2} + (w_{A}^{*}\\sigma(e_{A}))^{2}$$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2Ap0mqJJcn_",
        "outputId": "15f025c4-7312-4fa0-8922-41c2535ff63b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beta of Apple:  1.2353960938060866\n",
            "Alpha of Apple:  0.0007528131251585613\n",
            "Residual variance of Apple:  0.0001548384113993885\n",
            "-------------------------\n",
            "Beta of Google:  1.142061640295758\n",
            "Alpha of Google:  0.0002510766332060436\n",
            "Residual variance of Google:  0.00016078843613160276\n",
            "-------------------------\n",
            "Apple Weight: 4.861927465897098\n",
            "Google Weight: 1.5615341454067095\n",
            "Apple Weight Scaled: 0.7569014590732869\n",
            "Google Weight Scaled: 0.24309854092671315\n",
            "Alpha of the active portfolio:  0.0006308417160352167\n",
            "Residual variance of the active portfolio:  9.820899605363582e-05\n",
            "Initial position of active portfolio:  1.3076332565868463\n",
            "Beta of the active portfolio:  1.2127066243395337\n",
            "Adjusted position of the active portfolio:  1.029491000704147\n",
            "------------------------------\n",
            "Final Weights: \n",
            "Weight Market S&P:  -0.029491000704146897\n",
            "Weight Apple:  0.779223240535787\n",
            "Weight Google:  0.25026776016835994\n",
            "------------------------------\n",
            "Risk premium of portfolio:  0.06891230098019865\n",
            "Variance of portfolio:  0.01704347416145252\n"
          ]
        }
      ],
      "source": [
        "from pypfopt import plotting\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.svm import SVR\n",
        "from pypfopt import expected_returns, risk_models, EfficientFrontier\n",
        "\n",
        "# Returns of stocks and market\n",
        "apple_returns = ((apple_data['Close'] / apple_data['Close'].shift(1))-1).dropna().tolist()\n",
        "google_returns = ((google_data['Close'] / google_data['Close'].shift(1))-1).dropna().tolist()\n",
        "market_returns = ((market_index_data['Close'] / market_index_data['Close'].shift(1))-1).dropna().tolist()\n",
        "\n",
        "# Future marker returns prediction\n",
        "market_x = [market_returns[i:i+10] for i in range(len(market_returns)-20)]\n",
        "market_y = [market_returns[i+10] for i in range(10, len(market_returns)-10)]\n",
        "\n",
        "market_test = [market_returns[i:i+10]\n",
        "              for i in range(len(market_returns)-20, len(market_returns)-10)]\n",
        "\n",
        "reg = RandomForestRegressor()\n",
        "reg.fit(market_x, market_y)\n",
        "market_future = reg.predict(market_test)\n",
        "\n",
        "# Fitting single index model regression on market return and stock return\n",
        "single_index_reg_apple = LinearRegression()\n",
        "single_index_reg_apple.fit(np.array(market_returns).reshape(-1, 1),y=apple_returns)\n",
        "apple_future = single_index_reg_apple.predict(np.array(market_future).reshape(-1, 1))\n",
        "\n",
        "\n",
        "# Beta for apple stock\n",
        "beta_apple = single_index_reg_apple.coef_[0]\n",
        "# alpha for apple stock\n",
        "alpha_apple = single_index_reg_apple.intercept_\n",
        "print(\"Beta of Apple: \", beta_apple)\n",
        "print(\"Alpha of Apple: \", alpha_apple)\n",
        "\n",
        "y_pred = single_index_reg_apple.predict(np.array(market_returns).reshape(-1, 1))\n",
        "residuals = apple_returns - y_pred\n",
        "residual_variance_apple = np.var(residuals)\n",
        "\n",
        "# variance of the residuals for apple\n",
        "print(\"Residual variance of Apple: \", residual_variance_apple)\n",
        "print(\"-------------------------\")\n",
        "\n",
        "single_index_reg_google = LinearRegression()\n",
        "single_index_reg_google.fit(np.array(market_returns).reshape(-1, 1),google_returns)\n",
        "google_future = single_index_reg_google.predict(\n",
        "    np.array(market_future).reshape(-1, 1))\n",
        "\n",
        "# Beta for google stock\n",
        "beta_google = single_index_reg_google.coef_[0]\n",
        "# alpha for google stock\n",
        "alpha_google = single_index_reg_google.intercept_\n",
        "print(\"Beta of Google: \", beta_google)\n",
        "print(\"Alpha of Google: \", alpha_google)\n",
        "\n",
        "y_pred = single_index_reg_google.predict(np.array(market_returns).reshape(-1, 1))\n",
        "residuals = google_returns - y_pred\n",
        "residual_variance_google = np.var(residuals)\n",
        "\n",
        "# variance of the residuals for apple\n",
        "print(\"Residual variance of Google: \", residual_variance_google)\n",
        "print(\"-------------------------\")\n",
        "\n",
        "# Using Treynor Black model for portfolio optimization\n",
        "\n",
        "#STEP 1:\n",
        "# Compute the initial position of each security:\n",
        "w_apple = alpha_apple/residual_variance_apple\n",
        "w_google = alpha_google/residual_variance_google\n",
        "print(\"Apple Weight:\", w_apple)\n",
        "print(\"Google Weight:\", w_google)\n",
        "\n",
        "#STEP 2:\n",
        "# Scale the initial positions:\n",
        "w_apple_scaled = w_apple/(w_apple+w_google)\n",
        "w_google_scaled = w_google/(w_apple+w_google)\n",
        "print(\"Apple Weight Scaled:\", w_apple_scaled)\n",
        "print(\"Google Weight Scaled:\", w_google_scaled)\n",
        "\n",
        "#STEP 3:\n",
        "# Compute the alpha of the active portfolio:\n",
        "alpha_portfolio = w_apple_scaled*alpha_apple+w_google_scaled*alpha_google\n",
        "print(\"Alpha of the active portfolio: \", alpha_portfolio)\n",
        "\n",
        "#STEP 4:\n",
        "# Compute the residual variance of active portfolio:\n",
        "residual_variance_portfolio = w_apple_scaled*w_apple_scaled*residual_variance_apple + w_google_scaled*w_google_scaled*residual_variance_google\n",
        "print(\"Residual variance of the active portfolio: \", residual_variance_portfolio)\n",
        "\n",
        "#STEP 5:\n",
        "# Compute the initial position in active portfolio:\n",
        "# Note: The S&P 500‚Äôs long-term standard deviation (volatility) is around 12%. Hence, variance of S&P is 0.0114\n",
        "residual_variance_market = 0.0114\n",
        "risk_premium_market = 0.056\n",
        "initial_position_portfolio = (alpha_portfolio*residual_variance_market)/(residual_variance_portfolio*risk_premium_market)\n",
        "print(\"Initial position of active portfolio: \", initial_position_portfolio)\n",
        "\n",
        "#STEP 6:\n",
        "# Compute the beta of active portfolio:\n",
        "beta_portfolio = w_apple_scaled*beta_apple+w_google_scaled*beta_google\n",
        "print(\"Beta of the active portfolio: \", beta_portfolio)\n",
        "\n",
        "#STEP 7:\n",
        "# Adjust the initial position in active portfolio\n",
        "adjusted_position_portfolio = initial_position_portfolio/1+(1-beta_portfolio)*initial_position_portfolio\n",
        "print(\"Adjusted position of the active portfolio: \", adjusted_position_portfolio)\n",
        "\n",
        "#STEP 8:\n",
        "# Optimal risky portfolio now has weights:\n",
        "final_weight_market = 1-adjusted_position_portfolio\n",
        "final_weight_apple = adjusted_position_portfolio*w_apple_scaled\n",
        "final_weight_google = adjusted_position_portfolio*w_google_scaled\n",
        "\n",
        "print(\"------------------------------\")\n",
        "print(\"Final Weights: \")\n",
        "print(\"Weight Market S&P: \", final_weight_market)\n",
        "print(\"Weight Apple: \", final_weight_apple)\n",
        "print(\"Weight Google: \", final_weight_google)\n",
        "print(\"------------------------------\")\n",
        "\n",
        "\n",
        "#STEP 9:\n",
        "# Calculate the risk premium of P (Optimal risky portfolio):\n",
        "risk_premium_porfolio = (final_weight_market+adjusted_position_portfolio*beta_portfolio)*risk_premium_market + adjusted_position_portfolio*alpha_portfolio\n",
        "print(\"Risk premium of portfolio: \", risk_premium_porfolio)\n",
        "\n",
        "#STEP 10:\n",
        "# Compute the variance of Portfolio:\n",
        "portfolio_variance = (final_weight_market+adjusted_position_portfolio*beta_portfolio)*(final_weight_market+adjusted_position_portfolio*beta_portfolio)*residual_variance_market + adjusted_position_portfolio*adjusted_position_portfolio*residual_variance_portfolio\n",
        "print(\"Variance of portfolio: \", portfolio_variance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ab0NthVJcoA"
      },
      "source": [
        "# CAPM\n",
        "\n",
        "Similar to Single Index Model.\n",
        "\n",
        "Here the Regression equation is:\n",
        "\n",
        "$$R_{i} = R_{f} + Œ≤_{i} (R_{m} - R_{f})$$\n",
        "\n",
        "We will fit a linear regression for this equation to find $\\beta_{i}$\n",
        "$$R_{i} - R_{f} = Œ≤_{i} (R_{m} - R_{f}) + \\text{error}$$\n",
        "\n",
        "Here we are assuming the risk free rate of return($R_{f}$) as 0.01 - T-bill rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6nZ7N32JcoA",
        "outputId": "0bdb5ba2-908f-4ed0-a854-4ebdfcf1c13d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('apple', 0.9464), ('google', 0.0536)])\n"
          ]
        }
      ],
      "source": [
        "from pypfopt import expected_returns\n",
        "from pypfopt import plotting\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.linear_model import Ridge\n",
        "from pypfopt import expected_returns, risk_models, EfficientFrontier\n",
        "\n",
        "# T-bill rate\n",
        "risk_free_rate = 0.01\n",
        "\n",
        "apple_returns = (\n",
        "    (apple_data['Close'] / apple_data['Close'].shift(1))-1-risk_free_rate).dropna().tolist()\n",
        "google_returns = (\n",
        "    (google_data['Close'] / google_data['Close'].shift(1))-1-risk_free_rate).dropna().tolist()\n",
        "market_returns = (\n",
        "    (market_index_data['Close'] / market_index_data['Close'].shift(1))-1-risk_free_rate).dropna().tolist()\n",
        "\n",
        "# apple_prices = apple_data['Close'].tolist()\n",
        "# google_prices = google_data['Close'].tolist()\n",
        "market_x = [market_returns[i:i+10] for i in range(len(market_returns)-20)]\n",
        "market_y = [market_returns[i+10] for i in range(10, len(market_returns)-10)]\n",
        "\n",
        "market_test = [market_returns[i:i+10]\n",
        "               for i in range(len(market_returns)-20, len(market_returns)-10)]\n",
        "\n",
        "reg = MLPRegressor(hidden_layer_sizes=(100,100))\n",
        "reg.fit(market_x, market_y)\n",
        "market_future = reg.predict(market_test)\n",
        "\n",
        "# print(market_future)\n",
        "\n",
        "single_index_reg = Ridge()\n",
        "single_index_reg.fit(np.array(market_returns).reshape(-1, 1), y=apple_returns)\n",
        "apple_future = single_index_reg.predict(np.array(market_future).reshape(-1, 1))\n",
        "\n",
        "single_index_reg = Ridge()\n",
        "single_index_reg.fit(np.array(market_returns).reshape(-1, 1), google_returns)\n",
        "google_future = single_index_reg.predict(\n",
        "    np.array(market_future).reshape(-1, 1))\n",
        "\n",
        "future_returns = {'apple': apple, 'google': google}\n",
        "future_returns = pd.DataFrame(future_returns)\n",
        "\n",
        "\n",
        "S = risk_models.sample_cov(future_returns)\n",
        "# S = risk_models.CovarianceShrinkage(future_returns).ledoit_wolf()\n",
        "# plotting.plot_covariance(S, plot_correlation=True)\n",
        "# You don't have to provide expected returns in this case\n",
        "\n",
        "\n",
        "ef = EfficientFrontier(None, S)\n",
        "ef.min_volatility()\n",
        "weights = ef.clean_weights()\n",
        "print(weights)\n",
        "# weights = ef.max_sharpe(risk_free_rate=-0.2)\n",
        "# cleaned_weights = ef.clean_weights()\n",
        "# print(cleaned_weights)\n",
        "# print(mu)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWOKyy79JcoB"
      },
      "source": [
        "# Multifactor model\n",
        "\n",
        "- Load the market factors affecting your stocks : S&P 500(F1), GDP(F2), and 20+ Year Treasury Bond ETFs(F3)\n",
        "\n",
        "We have chosen these 3 factors randomly. S&P is the market factor, GDP is a macroeconomic factor and we have picked Treasury bond as the third factor.\n",
        "- Divide data into independent variable X (10 consecutive days of factor values), and dependent variable y (factor value at 10th day into future)\n",
        "- Train non linear regression model to predict market index value 10 day into the future\n",
        "- Fit separate linear models each for a stock according to formula of multi factor model\n",
        "- Here the linear equation is:\n",
        "$$r = E(r) + \\beta_{1}F_{1} + \\beta_{2}F_{2} + \\beta_{3}F_{3} + e$$\n",
        "E(r) = expected return on the security \\\\\n",
        "$F_{i}$ = the i-th factor \\\\\n",
        "$\\beta_{i}$ = the security‚Äôs sensitivity to movements in the i-th factor \\\\\n",
        "e = the idiosyncratic component of the security‚Äôs return\n",
        "- Find $\\beta_{i}$ from the fitted line to make the future predictions\n",
        "- Use 10 predicted factor returns to predict returns of each stock\n",
        "- Use the future returns of stocks to get stock weights using Mean Variance model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sk2EkrlcJcoB",
        "outputId": "764c9eca-cb44-4d5d-bdd4-8f50a54b75eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{2018: -0.8731875620129659, 2019: -0.23617811356352036, 2020: -1.5469812407578423, 2021: 0.43936719519542417, 2022: 0.8457453584592317, 2023: 1.3712343626796726}\n",
            "Coefficients for Apple stock:  [ 0.23225802 -0.03096973 -0.00047622]\n",
            "Coefficients for Google stock:  [ 2.14860963e-01 -2.50223907e-02 -1.32401069e-04]\n",
            "      apple    google\n",
            "0  0.000517  0.000480\n",
            "1  0.000908  0.000835\n",
            "2  0.000292  0.000272\n",
            "3  0.000660  0.000604\n",
            "4  0.000526  0.000487\n",
            "5  0.000580  0.000533\n",
            "6  0.000694  0.000639\n",
            "7  0.000419  0.000387\n",
            "8  0.000796  0.000737\n",
            "9  0.000488  0.000451\n",
            "             apple      google\n",
            "apple   112.212401  110.421241\n",
            "google  110.421241  108.688960\n",
            "apple     0.000588\n",
            "google    0.000542\n",
            "dtype: float64\n",
            "OrderedDict([('apple', 1.0), ('google', 0.0)])\n"
          ]
        }
      ],
      "source": [
        "from pypfopt import expected_returns\n",
        "from pypfopt import plotting\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.linear_model import Ridge\n",
        "from pypfopt import expected_returns, risk_models, EfficientFrontier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Example tickers for S&P 500, and 20+ Year Treasury Bond ETFs\n",
        "factor_tickers = ['SPY', 'TLT']\n",
        "\n",
        "# Fetch historical data for the macroeconomic factors S&P and Treasury Bond\n",
        "factor_data = yf.download(\n",
        "    factor_tickers, start=start_date, end=end_date, progress=False)\n",
        "factor_data = factor_data['Adj Close']\n",
        "\n",
        "# Calculate the returns for the S&P and Treasury bond factors\n",
        "factor_returns = factor_data.pct_change().dropna()\n",
        "spy_returns = factor_returns['SPY']\n",
        "tlt_returns = factor_returns['TLT']\n",
        "\n",
        "# FACTOR 1\n",
        "# Train ML model to predict future price of S&P market factors\n",
        "spy_x = [spy_returns[i:i+10] for i in range(len(spy_returns)-20)]\n",
        "spy_y = [spy_returns[i+10] for i in range(10, len(spy_returns)-10)]\n",
        "\n",
        "spy_test = [spy_returns[i:i+10]\n",
        "               for i in range(len(spy_returns)-20, len(spy_returns)-10)]\n",
        "reg = MLPRegressor(hidden_layer_sizes=(100, 100))\n",
        "reg.fit(spy_x, spy_y)\n",
        "spy_future = reg.predict(spy_test)\n",
        "\n",
        "# FACTOR 2\n",
        "# Train ML model to predict future price of Treasury Bond ETF factors\n",
        "tlt_x = [tlt_returns[i:i+10] for i in range(len(tlt_returns)-20)]\n",
        "tlt_y = [tlt_returns[i+10] for i in range(10, len(tlt_returns)-10)]\n",
        "\n",
        "tlt_test = [tlt_returns[i:i+10]\n",
        "               for i in range(len(tlt_returns)-20, len(tlt_returns)-10)]\n",
        "\n",
        "reg = MLPRegressor(hidden_layer_sizes=(100, 100))\n",
        "reg.fit(tlt_x, tlt_y)\n",
        "tlt_future = reg.predict(tlt_test)\n",
        "\n",
        "# FACTOR 3\n",
        "# GDP Price of USA for past 5 years\n",
        "\n",
        "# US GDP per capita Prices of last 5 years\n",
        "GDP_prices = {\n",
        "        2018: 59607,\n",
        "        2019: 60698,\n",
        "        2020: 58453,\n",
        "        2021: 61855,\n",
        "        2022: 62551,\n",
        "        2023: 63451 # Forecast data also available online\n",
        "    }\n",
        "\n",
        "# Normalize the GDP values as it will make the other factors irrelevant as it is very large\n",
        "values = list(GDP_prices.values())\n",
        "values_array = [[value] for value in values]\n",
        "scaler = StandardScaler()\n",
        "scaled_values = scaler.fit_transform(values_array)\n",
        "scaled_values = scaled_values.flatten()\n",
        "scaled_GDP_prices = {year: scaled_value for year, scaled_value in zip(GDP_prices.keys(), scaled_values)}\n",
        "\n",
        "print(scaled_GDP_prices)\n",
        "\n",
        "for index, row in factor_returns.iterrows():\n",
        "    # Extract the year from the date\n",
        "    year = index.year\n",
        "\n",
        "    # Fill the 'GDP' column with the corresponding GDP price based on the year\n",
        "    factor_returns.at[index, 'GDP'] = scaled_GDP_prices.get(year)\n",
        "\n",
        "future_factors = {'SPY': spy_future, 'TLT': tlt_future, 'GDP': [scaled_GDP_prices.get(2023)]*10}\n",
        "future_factors = pd.DataFrame(future_factors)\n",
        "#print(future_factors)\n",
        "\n",
        "# ùëü=ùê∏(ùëü)+ùõΩ1ùêπ1+ùõΩ2ùêπ2+ùõΩ3ùêπ3+ùëí : Fit linear model to find the betas for the 3 factors chosen\n",
        "# Fit Multi Factor Linear Regression model using Macroeconomic factors as X and stock returns as y\n",
        "apple_returns = (\n",
        "    (apple_data['Close'] / apple_data['Close'].shift(1))-1).dropna().tolist()\n",
        "google_returns = (\n",
        "    (google_data['Close'] / google_data['Close'].shift(1))-1).dropna().tolist()\n",
        "\n",
        "single_index_reg = Ridge()\n",
        "single_index_reg.fit(factor_returns, apple_returns)\n",
        "apple_future = single_index_reg.predict(future_factors)\n",
        "print(\"Coefficients for Apple stock: \", single_index_reg.coef_)\n",
        "\n",
        "single_index_reg = Ridge()\n",
        "single_index_reg.fit(factor_returns, google_returns)\n",
        "google_future = single_index_reg.predict(\n",
        "    future_factors)\n",
        "print(\"Coefficients for Google stock: \", single_index_reg.coef_)\n",
        "\n",
        "future_returns = {'apple': apple_future, 'google': google_future}\n",
        "# print(list(zip(apple,google)))\n",
        "future_returns = pd.DataFrame(future_returns)\n",
        "print(future_returns)\n",
        "\n",
        "S = risk_models.sample_cov(future_returns)\n",
        "print(S)\n",
        "# S = risk_models.CovarianceShrinkage(future_returns).ledoit_wolf()\n",
        "# plotting.plot_covariance(S, plot_correlation=True)\n",
        "# You don't have to provide expected returns in this case\n",
        "\n",
        "print(future_returns.mean())\n",
        "ef = EfficientFrontier(future_returns.mean(), S)\n",
        "# ef.min_volatility()\n",
        "# weights = ef.clean_weights()\n",
        "# print(weights)\n",
        "weights = ef.max_sharpe(risk_free_rate=0.0)\n",
        "cleaned_weights = ef.clean_weights()\n",
        "print(cleaned_weights)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23gEzgbzJcoB"
      },
      "source": [
        "# Equity valuation model - Dividend Model\n",
        "\n",
        "Equity valuation models are used to estimate the intrinsic value of a company's stock\n",
        "\n",
        "We are using the Dividend Discount Model (DDM):\n",
        "The Dividend Discount Model values a stock by calculating the present value of its future expected dividends\n",
        "\n",
        "The formula for the DDM is:\n",
        "\n",
        "$V = \\frac{D_{1}}{(r - g)}$\n",
        "\n",
        "Where:\n",
        "\n",
        "V is the intrinsic value of the stock \\\\\n",
        "D_{i} is the expected dividend per share in the next period \\\\\n",
        "r is the required rate of return or the discount rate \\\\\n",
        "g is the expected growth rate of dividends\n",
        "\n",
        "- Load dividend values of your stock\n",
        "- Identify the period of change and only keep unique values in a period\n",
        "- Train non linear regression model to predict next dividend value\n",
        "- Calculate average dividend growth rate of your stock\n",
        "- Assume a discount rate for the stock\n",
        "- Use ML model to predict next dividend value\n",
        "- Use the predicted dividend value, discount rate and average dividend growth rate to find stock price\n",
        "\n",
        "**Note:**\n",
        "\n",
        "We will use the intrinsic stock value returned by the Equity valuation model as input to the Subjective views dictionary of black litterman model for portfolio allocation."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the results of the instrinsic value of stock from the equity valuation model and by comparing it with the current stock price, we can decide to whether buy or sell the stocks. Using these intrinsic values, weights or constraints can be added in the black litterman model."
      ],
      "metadata": {
        "id": "Dfm183i1ENNg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOiHhIN2JcoB",
        "outputId": "d6a46f41-ce83-49b7-a825-73fc80cf558c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-70-30752c6d853a>:12: FutureWarning: Indexing a timezone-aware DatetimeIndex with a timezone-naive datetime is deprecated and will raise KeyError in a future version. Use a timezone-aware object instead.\n",
            "  apple_dividends = apple_stock.dividends.loc[start_date:end_date]\n",
            "<ipython-input-70-30752c6d853a>:17: FutureWarning: Indexing a timezone-aware DatetimeIndex with a timezone-naive datetime is deprecated and will raise KeyError in a future version. Use a timezone-aware object instead.\n",
            "  microsoft_dividends = microsoft_stock.dividends.loc[start_date:end_date]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dividend Growth rate: \n",
            " AAPL    0.056367\n",
            "MSFT    0.101178\n",
            "dtype: float64\n",
            "Predicted next period dividend for APPLE 0.949999999999999\n",
            "Predicted next period dividend for Microsoft 2.6151999999999997\n",
            "Intrinsic Value of Apple Stock: 43.91362822272131\n",
            "Intrinsic Value of Microsoft Stock: 296.4408090632195\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "---------------------------------------------\n",
            "Final weights in the portfolio allocation: \n",
            "OrderedDict([('AAPL', 0.42874), ('MSFT', 0.57126)])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pypfopt/efficient_frontier/efficient_frontier.py:259: UserWarning: max_sharpe transforms the optimization problem so additional objectives may not work as expected.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from pypfopt import BlackLittermanModel, plotting\n",
        "from pypfopt import black_litterman, risk_models\n",
        "\n",
        "microsoft_data = yf.download('MSFT', start=start_date, end=end_date)\n",
        "\n",
        "# get dividends of the Apple stock\n",
        "apple_stock = yf.Ticker(apple_ticker)\n",
        "apple_dividends = apple_stock.dividends.loc[start_date:end_date]\n",
        "apple_dividends = apple_dividends.reset_index(drop=True)\n",
        "\n",
        "# get dividends of the Microsoft stock\n",
        "microsoft_stock = yf.Ticker('MSFT')\n",
        "microsoft_dividends = microsoft_stock.dividends.loc[start_date:end_date]\n",
        "microsoft_dividends = microsoft_dividends.reset_index(drop=True)\n",
        "\n",
        "# Combine the dividend data into a single DataFrame (We are multiplying by 4 as these are quarterly dividends)\n",
        "dividends = pd.DataFrame({'AAPL':apple_dividends*4, 'MSFT':microsoft_dividends*4})\n",
        "#print(dividends)\n",
        "\n",
        "# Calculate the dividend growth rates\n",
        "dividend_growth_rates = dividends.pct_change().dropna()\n",
        "\n",
        "# Since we only have dividend changes every 4 months, we remove the 0 values and get the average dividend growth rate which we consider as perpetual growth rate\n",
        "avg_dividends_growth_rate = dividend_growth_rates.mask(dividend_growth_rates == 0).sum()/5\n",
        "\n",
        "print(\"Dividend Growth rate: \\n\", avg_dividends_growth_rate)\n",
        "\n",
        "# PREDICTING NEXT DIVIDEND VALUE FOR APPLE STOCK\n",
        "\n",
        "# Define the features and target variable for the machine learning model\n",
        "X = np.unique(dividends['AAPL'].values)[:-1]  # Independent variables (dividend value for the past period)\n",
        "y = np.unique(dividends['AAPL'].values)[1:]  # Dependent variable (dividend value for the next period)\n",
        "\n",
        "# Train a machine learning model using regression to predict the next dividend value\n",
        "model = RandomForestRegressor()\n",
        "model.fit(X.reshape(-1,1), y)\n",
        "\n",
        "# Use the trained model to predict the dividend value for the next period\n",
        "next_period_dividend_apple = model.predict(dividends['AAPL'].values[-1].reshape(1, -1))[0]\n",
        "print(\"Predicted next period dividend for APPLE\", next_period_dividend_apple)\n",
        "\n",
        "# PREDICTING NEXT DIVIDEND VALUE FOR MICROSOFT STOCK\n",
        "\n",
        "# Define the features and target variable for the machine learning model\n",
        "X = np.unique(dividends['MSFT'].values)[:-1]  # Independent variables (dividend value for the past period)\n",
        "y = np.unique(dividends['MSFT'].values)[1:]  # Dependent variable (dividend value for the next period)\n",
        "\n",
        "# Train a machine learning model using regression to predict the next dividend value\n",
        "model = RandomForestRegressor()\n",
        "model.fit(X.reshape(-1,1), y)\n",
        "\n",
        "# Use the trained model to predict the dividend value for the next period\n",
        "next_period_dividend_microsoft = model.predict(dividends['MSFT'].values[-1].reshape(1, -1))[0]\n",
        "print(\"Predicted next period dividend for Microsoft\", next_period_dividend_microsoft)\n",
        "\n",
        "# Apply the DDM formula to calculate the intrinsic value of the stocks\n",
        "discount_rate = 0.078  # Available online\n",
        "apple_intrinsic_price = next_period_dividend_apple / \\\n",
        "    (discount_rate - avg_dividends_growth_rate['AAPL'])\n",
        "\n",
        "discount_rate = 0.11\n",
        "microsoft_intrinsic_price = next_period_dividend_microsoft / \\\n",
        "    (discount_rate - avg_dividends_growth_rate['MSFT'])\n",
        "\n",
        "print(\"Intrinsic Value of Apple Stock:\", apple_intrinsic_price)\n",
        "print(\"Intrinsic Value of Microsoft Stock:\", microsoft_intrinsic_price)\n",
        "\n",
        "# We can notice that the intrinsic stock values for both Apple and Microsoft are over-valued which makes sense as they are at their all-time high.\n",
        "\n",
        "# Use the intrinsic value of stock as views for BL model\n",
        "# Here We are filling our subjective views based on the fair price of the stocks that we calculated using Equity evaluation model\n",
        "viewdict = {'AAPL': apple_intrinsic_price/apple_data['Close'][-1], 'MSFT': microsoft_intrinsic_price/microsoft_data['Close'][-1]}\n",
        "tickers = ['AAPL','MSFT']\n",
        "mcaps = {}\n",
        "for t in tickers:\n",
        "    stock = yf.Ticker(t)\n",
        "    mcaps[t] = stock.info[\"marketCap\"]\n",
        "# print(mcaps)\n",
        "\n",
        "prices = pd.DataFrame({'AAPL':apple_data['Close'].values,'MSFT':microsoft_data['Close'].values})\n",
        "S = risk_models.CovarianceShrinkage(prices).ledoit_wolf()\n",
        "market_prices = yf.download(\"SPY\", period=\"max\")[\"Adj Close\"]\n",
        "\n",
        "\n",
        "delta = black_litterman.market_implied_risk_aversion(market_prices)\n",
        "# print(delta)\n",
        "market_prior = black_litterman.market_implied_prior_returns(mcaps, delta, S)\n",
        "# print(market_prior)\n",
        "\n",
        "# Assign confidence measure for stock returns based on some heuristics\n",
        "confidences = [\n",
        "    0.6,\n",
        "    0.4\n",
        "]\n",
        "\n",
        "# Fit BL model\n",
        "bl = BlackLittermanModel(S, pi=market_prior, absolute_views=viewdict, omega=\"idzorek\", view_confidences=confidences)\n",
        "\n",
        "# Get expected returns\n",
        "ret_bl = bl.bl_returns()\n",
        "# print(ret_bl)\n",
        "\n",
        "# Get cov matrix\n",
        "S_bl = bl.bl_cov()\n",
        "\n",
        "\n",
        "from pypfopt import EfficientFrontier, objective_functions\n",
        "\n",
        "ef = EfficientFrontier(ret_bl, S_bl)\n",
        "ef.add_objective(objective_functions.L2_reg)\n",
        "ef.max_sharpe()\n",
        "weights = ef.clean_weights()\n",
        "print(\"---------------------------------------------\")\n",
        "print(\"Final weights in the portfolio allocation: \")\n",
        "print(weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yy4SQlFKJcoB"
      },
      "source": [
        "# Black litterman model\n",
        "\n",
        "In this model, we are using Machine learning to forecast the returns and using that to fill the subjective views(confidence)\n",
        "\n",
        "- Use non linear ML model to predict stock prices in future (same as we did in mean-variance section)\n",
        "- Use the predicted future return of stocks as you \"views\" for black litterman model\n",
        "- Assign confidence using accuracy of your ML model or arbitrarily based on your market understanding\n",
        "- Fit the Black litterman model and calculate corresponding cov matrix and returns\n",
        "- Find the optimal weights using bl cov matrix and returns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoGsdAZqJcoC",
        "outputId": "59dfdc1a-dbc0-4a01-a670-218389c9769a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0005149357850170555 -0.007898421716305592\n",
            "{'AAPL': 2957939310592, 'GOOGL': 1506293579776}\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "2.581431738882907\n",
            "AAPL     0.273215\n",
            "GOOGL    0.233136\n",
            "dtype: float64\n",
            "AAPL     0.092459\n",
            "GOOGL    0.082701\n",
            "dtype: float64\n",
            "OrderedDict([('AAPL', 0.53921), ('GOOGL', 0.46079)])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pypfopt/efficient_frontier/efficient_frontier.py:259: UserWarning: max_sharpe transforms the optimization problem so additional objectives may not work as expected.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from pypfopt import BlackLittermanModel, plotting\n",
        "from pypfopt import black_litterman, risk_models\n",
        "\n",
        "# Fit non linear ML models to predict stock returns into future\n",
        "apple_returns = (\n",
        "    (apple_data['Close'] / apple_data['Close'].shift(1))-1).dropna().tolist()\n",
        "google_returns = (\n",
        "    (google_data['Close'] / google_data['Close'].shift(1))-1).dropna().tolist()\n",
        "\n",
        "apple_x = [apple_returns[i:i+10] for i in range(len(apple_returns)-20)]\n",
        "apple_y = [apple_returns[i+10] for i in range(10,len(apple_returns)-10)]\n",
        "\n",
        "apple_test = [apple_returns[i:i+10] for i in range(len(apple_returns)-20,len(apple_returns)-10)]\n",
        "\n",
        "reg = RandomForestRegressor()\n",
        "reg.fit(apple_x,apple_y)\n",
        "apple = reg.predict(apple_test)\n",
        "\n",
        "google_x = [google_returns[i:i+10] for i in range(len(google_returns)-20)]\n",
        "google_y = [google_returns[i+10] for i in range(10,len(google_returns)-10)]\n",
        "\n",
        "google_test = [google_returns[i:i+10] for i in range(len(google_returns)-20,len(google_returns)-10)]\n",
        "\n",
        "reg = RandomForestRegressor()\n",
        "reg.fit(google_x,google_y)\n",
        "google = reg.predict(google_test)\n",
        "\n",
        "future_returns = {'apple':apple,'google':google}\n",
        "print(apple[-1],google[-1])\n",
        "\n",
        "# Use predicted future returns as views for BL model\n",
        "viewdict = {'AAPL': apple[-1], 'GOOGL': google[-1]}\n",
        "tickers = ['AAPL','GOOGL']\n",
        "mcaps = {}\n",
        "for t in tickers:\n",
        "    stock = yf.Ticker(t)\n",
        "    mcaps[t] = stock.info[\"marketCap\"]\n",
        "print(mcaps)\n",
        "\n",
        "prices = pd.DataFrame({'AAPL':apple_data['Close'].values,'GOOGL':google_data['Close'].values})\n",
        "S = risk_models.CovarianceShrinkage(prices).ledoit_wolf()\n",
        "market_prices = yf.download(\"SPY\", period=\"max\")[\"Adj Close\"]\n",
        "\n",
        "\n",
        "delta = black_litterman.market_implied_risk_aversion(market_prices)\n",
        "print(delta)\n",
        "market_prior = black_litterman.market_implied_prior_returns(mcaps, delta, S)\n",
        "print(market_prior)\n",
        "\n",
        "# Assign confidence measure for stock returns based on some heuristics\n",
        "confidences = [\n",
        "    0.6,\n",
        "    0.4\n",
        "]\n",
        "\n",
        "# Fit BL model\n",
        "bl = BlackLittermanModel(S, pi=market_prior, absolute_views=viewdict, omega=\"idzorek\", view_confidences=confidences)\n",
        "\n",
        "# Get expected returns\n",
        "ret_bl = bl.bl_returns()\n",
        "print(ret_bl)\n",
        "\n",
        "# Get cov matrix\n",
        "S_bl = bl.bl_cov()\n",
        "\n",
        "\n",
        "from pypfopt import EfficientFrontier, objective_functions\n",
        "\n",
        "ef = EfficientFrontier(ret_bl, S_bl)\n",
        "ef.add_objective(objective_functions.L2_reg)\n",
        "ef.max_sharpe()\n",
        "weights = ef.clean_weights()\n",
        "print(weights)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x09FDy_AJcoC"
      },
      "source": [
        "# Algorithmic trading - Using Bollinger Bands (You can use any alternative approach like EMA etc)\n",
        "\n",
        "- Install talib to calculate Bollinger Bands\n",
        "- Calculate Bollinger bands for your stock using historical data\n",
        "- Divide data into independent variable X (stock prices) and dependent variable y (sell -1 if stock price > upper limit of bollinger band, buy 1 otherwise)\n",
        "- Train a classifier to predict the buy or sell based on stock price\n",
        "- Use the trained classifier to trade the stock in real time\n",
        "- The algorithmic trading is more useful in intra day or high frequency trading scenario and is not generally done for long term portfolio holdings\n",
        "- However, you can buy or sell the complete stock based on this everyday to maximize your capital"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install this package on your system: https://pypi.org/project/TA-Lib/"
      ],
      "metadata": {
        "id": "Gcrb7MaLDxoo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2VzOdY-JcoC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import talib\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "apple_prices = apple_data['Close']\n",
        "\n",
        "# Calculate Bollinger Bands for Apple\n",
        "apple_bb_upper, apple_bb_middle, apple_bb_lower = talib.BBANDS(\n",
        "    apple_prices, timeperiod=20)\n",
        "\n",
        "\n",
        "# Calculate the Bollinger Bands percentages for Apple\n",
        "apple_bb_percentage = (apple_prices - apple_bb_lower) / \\\n",
        "    (apple_bb_upper - apple_bb_lower)\n",
        "\n",
        "# # Combine the Bollinger Bands percentages into a single DataFrame\n",
        "# bb_percentages = pd.concat(\n",
        "#     [apple_bb_percentage, google_bb_percentage], axis=1).dropna()\n",
        "\n",
        "# Define the features and target variable for the machine learning model\n",
        "# Independent variables (Bollinger Bands percentages for the past period)\n",
        "X = apple_bb_percentage.values[:-1]\n",
        "# Target variable (-1 for sell, 1 for buy)\n",
        "y = np.where(apple_prices.values[1:] > apple_bb_upper[:-1], -1, 1)\n",
        "\n",
        "# Train a machine learning model using random forest classifier\n",
        "model = RandomForestClassifier(n_estimators=100)\n",
        "model.fit(X, y)\n",
        "\n",
        "# Use the trained model to predict the trading signals for the testing set\n",
        "# Ideally this will be your real time stock prices\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Perform algorithmic trading based on the predicted signals (example logic)\n",
        "capital = 100000  # Initial capital in USD\n",
        "position = 0  # Current position (0 for neutral, 1 for long, -1 for short)\n",
        "\n",
        "for i in range(len(y_pred)):\n",
        "    if y_pred[i] == 1 and position != 1:  # Buy signal\n",
        "        position = 1\n",
        "        # Place a buy order based on your trading platform's API or logic\n",
        "\n",
        "    elif y_pred[i] == -1 and position != -1:  # Sell signal\n",
        "        position = -1\n",
        "        # Place a sell order based on your trading platform's API or logic\n",
        "\n",
        "    elif y_pred[i] == 0 and position != 0:  # Exit position\n",
        "        position = 0\n",
        "        # Close the existing position based on your trading platform's API or logic\n",
        "\n",
        "# Calculate the final capital after the trading period\n",
        "final_capital = capital  # Assume no transaction costs or slippage\n",
        "# Calculate the final capital based on your trading platform's API or logic\n",
        "\n",
        "print(\"Final Capital:\", final_capital)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "2022.10.undefined"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}